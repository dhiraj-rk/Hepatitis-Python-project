{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd920e7",
   "metadata": {},
   "source": [
    "# Python Project on Hepatitis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d645eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be10370",
   "metadata": {},
   "source": [
    "# 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9601348",
   "metadata": {},
   "source": [
    "The given dataset - Hepatits Domain provides the dataset with various attributes and also provides if the patient with the disease was a survivor or not under Class atrribute. The dataset is used to conduct various data analysis procedures such as data inspection, exploration, standardizing and handling outlilers. Based on the analysis we made from our previous processes, the results are summarized.\n",
    "\n",
    "The project is divided in to three sections - Introduction, Analysis and Conclusion. This introduction section mainly deals with data introduction and preprocessing. A brief overview of how the data is tabulated, what features does it have and what statistical values it provides are examined. Based on that, some pre-processing and data cleaning is done to get the dataset to be in the best possible form to conduct further examination. \n",
    "\n",
    "Analysis section contains some graphs and Exploratory Data Analysis to see more indepth about the features. We visualize dataset to understand their main characteristics, identify patterns and spot anomalies.\n",
    "\n",
    "Finally, based on the preprocessing and analysis, we conclude our findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20942c",
   "metadata": {},
   "source": [
    "### 1.1. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hepatitis.txt\", header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d00cf",
   "metadata": {},
   "source": [
    "### 1.2. Assigning column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Class', 'Age', 'Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver_Big','Liver_Firm',\n",
    "             'Spleen_Palpable', 'Spiders', 'Ascites', 'Varices', 'Bilirubin', 'Alk_Phosphate', 'Sgot','Albumin', 'Protime', \n",
    "             'Histology'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f91b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns = col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe7aef",
   "metadata": {},
   "source": [
    "### 1.3. General Description of dataset and handling anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e1726",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8839af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc5044",
   "metadata": {},
   "source": [
    "The table above gives statistical description of the data with the number of observations in each numeric column, their mean, standard deviation, minimum and maximum values along with the quartiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e7362",
   "metadata": {},
   "source": [
    "#### Shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbfddb",
   "metadata": {},
   "source": [
    "The dataset consists of 155 rows and 20 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065eaf1",
   "metadata": {},
   "source": [
    "#### Handling missing or misleading values\n",
    "The dataset contains '?' or '.' or '9999' or '99999' as values for some observations. First, replacing these with NaN values and counting the total missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faecffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.replace('?', np.nan)\n",
    "df1 = df1.replace('.', np.nan)\n",
    "df1 = df1.replace(9999, np.nan)\n",
    "df1 = df1.replace(99999, np.nan)\n",
    "\n",
    "nan_counts = df1.isna().sum()\n",
    "missing_data = pd.DataFrame((df1.isnull().sum()) * 100 / df1.shape[0]).reset_index()\n",
    "print(f\"NaN Count\\n{nan_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b2feb",
   "metadata": {},
   "source": [
    "Displaying all the rows and columns of the dataset to inspect and verify missing and misleading values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9196ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49e38f",
   "metadata": {},
   "source": [
    "#### Overview of the datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b62c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting categorical columns\n",
    "categorical_cols = df1.select_dtypes(include=['object']).columns\n",
    "print(categorical_cols)\n",
    "\n",
    "#Getting numerical columns\n",
    "numerical_cols = df1.select_dtypes(include=['int', 'float']).columns\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f384faa",
   "metadata": {},
   "source": [
    "As seen from above, 16 variables are classified as categorical columns and 4 variables are numerical variables in the dataset. To generalize, the original dataset has been copied to a new one and all of the parameters will be converted to float type for ease of data cleaning for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6779298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted = df1.copy()\n",
    "df_converted[categorical_cols] = df_converted[categorical_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c08cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_converted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8a8b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_converted.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e034b56",
   "metadata": {},
   "source": [
    "It looked like some of the columns - Malaise, Spiders and Alk_Phosphate at rows 24, 130 and 135 still have data with 9999 or 99999 on them. Carrying our more data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced896b",
   "metadata": {},
   "source": [
    "#### Handling more missing or misleading values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c022bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace(9999, np.nan, inplace = True)\n",
    "df1.replace(99999, np.nan, inplace = True)\n",
    "df1.replace('9999', np.nan, inplace = True)\n",
    "df1.replace('99999', np.nan, inplace = True)\n",
    "nan_counts = df1.isna().sum()\n",
    "missing_data = pd.DataFrame((df1.isnull().sum())*100/df1.shape[0]).reset_index()\n",
    "print(f\"NaN Count\\n{nan_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7167914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644cacf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for column in df1.columns:\n",
    " #   has_question_mark = \"?\" in df1[column].values\n",
    "  #  has_dot = \".\" in df1[column].values\n",
    "   # has_9999 = 9999 in df1[column].values\n",
    "    #has_99999 = 99999 in df1[column].values\n",
    "\n",
    "    #print(f\"Column: {column}\")\n",
    "    #print(f\"Contains '?' : {has_question_mark}\")\n",
    "    #print(f\"Contains '.' : {has_dot}\")\n",
    "    #print(f\"Contains 9999 : {has_9999}\")\n",
    "    #print(f\"Contains 99999 : {has_99999}\")\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bbea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "table_rows = []\n",
    "\n",
    "for column in df1.columns:\n",
    "    contains_question_mark = \"?\" in df1[column].values\n",
    "    contains_dot = \".\" in df1[column].values\n",
    "    contains_9999 = 9999 in df1[column].values\n",
    "    contains_99999 = 99999 in df1[column].values\n",
    "    contains_9999_str = \"9999\" in df1[column].values\n",
    "    contains_99999_str = \"99999\" in df1[column].values\n",
    "    \n",
    "    table_rows.append([column, contains_question_mark, contains_dot, contains_9999, contains_99999, contains_9999_str, contains_99999_str])\n",
    "\n",
    "headers = [\"Column\", \"Contains '?'\", \"Contains '.'\", \"Contains 9999\", \"Contains 99999\", \"Contains str_9999\", \"Contains str_99999\"]\n",
    "\n",
    "print(tabulate(table_rows, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN Counts:\",df1.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bcc237",
   "metadata": {},
   "source": [
    "Now the data has been cleaned of all the misleading values. Next is cleaning the data of all NaN values with backfill method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917317dc",
   "metadata": {},
   "source": [
    "#### Replacing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb960c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.bfill()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171619dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN Counts:\",df2.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4b140",
   "metadata": {},
   "source": [
    "It seems like all the NaN values have been replaced with the backfill method and also there are no '.', '?', '9999' or '99999' values any longer in the dataset to give us misleading information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da528fc",
   "metadata": {},
   "source": [
    "# 2. DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d893f6",
   "metadata": {},
   "source": [
    "### 2.1. Changing categorical variables to numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a933d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values in the columns before conversion\n",
    "#for col in numerical_cols_to_convert:\n",
    " #   print(f\"\\nUnique values in '{col}' before conversion:\")\n",
    "#    print(df3[col].unique())\n",
    "\n",
    "# Convert columns to regular numerical values in a loop\n",
    "for col in categorical_cols:\n",
    "    df3[col] = pd.to_numeric(df3[col], errors='coerce')\n",
    "\n",
    "# Display unique values in the columns after conversion\n",
    "#for col in numerical_cols_to_convert:\n",
    " #   print(f\"\\nUnique values in '{col}' after conversion:\")\n",
    " #   print(df3[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9412e1e",
   "metadata": {},
   "source": [
    "### 2.2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35ada0",
   "metadata": {},
   "source": [
    "#### Generating correlation matrix and correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106d532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df3.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd646a5",
   "metadata": {},
   "source": [
    "From the correlation heatmap, we can see most of the columns have a relatively low correlation with each other. But some columns do have a positive correlation coefficient up to 0.59 which is not a concerning factor. Therefore, we can say that there is not a very strong correlation between the different columns. Some of the highlights are:\n",
    "Class:\n",
    "Strong negative correlation with 'Bilirubin' (-0.44), 'Histology' (-0.34), and 'Ascites' (-0.47).\n",
    "Strong positive correlation with 'Ascites' (0.47), 'Spiders' (0.38), 'Varices' (0.36), and 'Albumin' (0.38).\n",
    "\n",
    "Age:\n",
    "Weak negative correlations with 'Class' (-0.25) and 'Albumin' (-0.25).\n",
    "Weak positive correlation with 'Spiders' (0.31).\n",
    "\n",
    "Fatigue:\n",
    "Moderate positive correlations with 'Class' (0.31), 'Malaise' (0.33), 'Spiders' (0.38), 'Ascites' (0.47), 'Varices' (0.36), and 'Albumin' (0.38).\n",
    "Weak negative correlation with 'Sgot' (-0.20).\n",
    "\n",
    "Malaise:\n",
    "Moderate positive correlations with 'Class' (0.33), 'Fatigue' (0.58), 'Spiders' (0.31), 'Ascites' (0.31), 'Varices' (0.16), and 'Albumin' (0.26).\n",
    "\n",
    "Spiders:\n",
    "Strong positive correlations with 'Class' (0.38), 'Fatigue' (0.38), 'Malaise' (0.31), 'Ascites' (0.29), 'Varices' (0.38), and 'Albumin' (0.31).\n",
    "\n",
    "Ascites:\n",
    "Strong positive correlations with 'Class' (0.47), 'Fatigue' (0.29), 'Malaise' (0.31), 'Spiders' (0.29), 'Varices' (0.37), and 'Albumin' (0.47).\n",
    "Weak negative correlation with 'Sgot' (-0.27).\n",
    "\n",
    "Varices:\n",
    "Strong positive correlations with 'Class' (0.36), 'Fatigue' (0.18), 'Malaise' (0.16), 'Spiders' (0.38), 'Ascites' (0.37), and 'Albumin' (0.36).\n",
    "Strong negative correlation with 'Bilirubin' (-0.37).\n",
    "\n",
    "Bilirubin:\n",
    "Strong negative correlations with 'Class' (-0.44), 'Albumin' (-0.40), and 'Sgot' (-0.40).\n",
    "Moderate positive correlation with 'Histology' (0.28).\n",
    "\n",
    "Sgot:\n",
    "Weak negative correlation with 'Class' (-0.06).\n",
    "Moderate positive correlation with 'Bilirubin' (0.40).\n",
    "Weak negative correlation with 'Ascites' (-0.27).\n",
    "\n",
    "Albumin:\n",
    "Strong positive correlations with 'Class' (0.38), 'Fatigue' (0.29), 'Malaise' (0.26), 'Spiders' (0.31), 'Ascites' (0.47), and 'Varices' (0.36).\n",
    "Strong negative correlation with 'Bilirubin' (-0.40).\n",
    "\n",
    "Histology:\n",
    "Strong negative correlations with 'Class' (-0.34), 'Bilirubin' (0.28), 'Sgot' (0.13), 'Alk_Phosphate' (0.14), and 'Protime' (-0.38).\n",
    "Weak positive correlation with 'Sex' (-0.14)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9a996",
   "metadata": {},
   "source": [
    "We will take the parameter \"CLASS\" as our response variable as it makes sense that our prediction is to see if a patient who has incurred Hepatitis is likely to survive or decease. Based on that, taking a look at some EDA. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef66bb4",
   "metadata": {},
   "source": [
    "#### Correlation matrix with \"CLASS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df3.corr()\n",
    "\n",
    "correlation_with_class = correlation_matrix['Class']\n",
    "\n",
    "print(\"\\nCorrelation with the 'Class' column:\")\n",
    "print(correlation_with_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910a9e6",
   "metadata": {},
   "source": [
    "Above is the correlation matrix of each parameter with Class. The parameters - Age, Antivirals, Liver_Big, Bilirubin, Alk_phosphate, Sgot, Histology are negetively correlated with the Class parameter. This means these columns are as the value for these columns increase, the likelihood of being in \"Live\" category of Class parameter may slightly decrease. Similarly the other columns have positive correlation with the Class incurring that with the increase in values for those columns the likelihood of being in \"Live\" category of Class parameter also increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0f28d",
   "metadata": {},
   "source": [
    "#### Ratio of patients who die or live after contracting Hepatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9668b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = df3.shape[0]\n",
    "survivors = (np.sum(df3['Class'] == 2)/patients)*100\n",
    "non_survivors = (np.sum(df3['Class'] == 1)/patients)*100\n",
    "print(f\"Survivors:{survivors:.2f}%\")\n",
    "print(f\"Non_survivors: {non_survivors:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58dd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df3['Class'].value_counts()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"Set2\")\n",
    "\n",
    "plt.xlabel(\"Class\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.title(\"Count of TARGET Variable per Class\", fontsize=16)\n",
    "    \n",
    "plt.xticks([0, 1], ['DIE', 'LIVE'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43fd97",
   "metadata": {},
   "source": [
    "From the document we know, 1 = DIE and 2 = LIVE. It seems like more people live even after contracting Hepatitis i.e. 123 people have lived which accounts for around 79.35% and 32 have died which accounts for around 20.65% of the total patients. The bar graph clearly gives a visual representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e77ce",
   "metadata": {},
   "source": [
    "#### Distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66440840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0706161",
   "metadata": {},
   "source": [
    "Since, 'Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime' are the only ones with non-boolean values, we categorize them separately to conduct some analysis. And leave the rest of the columns to do their own separate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime']\n",
    "nonnum_vars = ['Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver_Big',\n",
    "           'Liver_Firm', 'Spleen_Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057416b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(num_vars[0:]):\n",
    "    sns.histplot(data=df3, x=column, stat='probability', kde=True, ax=axes[i], hue='Class', common_norm=False, palette=\"Set2\")\n",
    "\n",
    "    axes[i].set_title(f'Histogram of {column}')\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('')\n",
    "    axes[i].legend(title='Class', labels=['Class 1', 'Class 2'])\n",
    "    axes[i].tick_params(axis='x', rotation=90)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111a3b3",
   "metadata": {},
   "source": [
    "#### Description for 'Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d5634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3[num_vars].describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167f43a",
   "metadata": {},
   "source": [
    "The above histograms show the distribution of data for 'Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime'. As we can see, the distribution of Age is almost normal. For Age, Bilirubin, Alk_Phosphate and SGOT, it is skewed towards the right side. And we can also see for these column the mean is greater than median value. For Albumin and Protime, the mean is smaller in value than median which is also indicated in the histogram for these columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38f0ed",
   "metadata": {},
   "source": [
    "### 2.3. Outlier checking and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf22368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(num_vars[0:]):\n",
    "    sns.boxplot(x='Class', y=column, data=df3, hue='Class', ax=axes[i]).set_title(f\"{column} Outlier Detection\")\n",
    "\n",
    "    axes[i].set_xlabel('CLASS')\n",
    "    axes[i].set_ylabel(column)\n",
    "    axes[i].legend(title='CLASS')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282a5e5",
   "metadata": {},
   "source": [
    "As we can see from the above boxplots, \"Age\" does not have any outliers. \"Bilirubin\" has some outliers for both the values of \"Class\" parameter\". \"Alk_Phosphate\" has one for \"Die\" value of \"Class\" and some for \"Live\" value of \"Class\". \"SGOT\" also has some outliers for both values of \"Class\". \"Albumin\" has some outliers outside of the upper and lower range of \"Live\" value of \"Class\" parameter. And \"Protime\" has one below the lower bound for \"Live\" value of \"Class\" parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09142df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df3[num_vars].quantile(0.25)\n",
    "Q3 = df3[num_vars].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "def filter_outliers(column):\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "    return (df3[column] >= lower_bound) & (df3[column] <= upper_bound)\n",
    "\n",
    "outlier_filter = pd.DataFrame()\n",
    "for column in num_vars:\n",
    "    outlier_filter[column] = filter_outliers(column)\n",
    "\n",
    "#print(\"Outlier Filter DataFrame:\")\n",
    "#print(outlier_filter)\n",
    "\n",
    "df_no_outliers = df3[outlier_filter.all(axis=1)]\n",
    "\n",
    "print(\"Original DataFrame shape:\", df3.shape)\n",
    "print(\"DataFrame shape after removing outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba131b0",
   "metadata": {},
   "source": [
    "Therefore, the size of the dataframe has been reduced from 155 to 117 after removing all the outliers from 'Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b864143",
   "metadata": {},
   "source": [
    "#### Diagrams for non-numeric variables 'Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver_Big', 'Liver_Firm', 'Spleen_Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e621e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_subplots = len(nonnum_vars)\n",
    "num_rows = 3\n",
    "num_cols = 5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(18, 4 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(nonnum_vars):\n",
    "    if i < num_subplots:\n",
    "        sns.countplot(data=df_no_outliers, x=column, hue='Class', palette='Set2', ax=axes[i])\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_title(f'Count Plot of {column} with respect to Class')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].legend(title='Class', loc='upper right')\n",
    "    else:\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3be561",
   "metadata": {},
   "source": [
    "The histograms show the distribution of each of the mentioned variables with respect to \"Class\" (1 = Die, 2 = Live)\n",
    "From the diagrams above, we can see the following patterns:\n",
    "\n",
    "1. Sex (1 = Male, 2 = Female): The majority of individuals in the dataset are male compared to female. And it seems like some male patients have also died because of the disease.\n",
    "\n",
    "2. Steroid (1 = No, 2 = Yes): Most individuals have positive value for steroids. Class distribution appears balanced between those who have taken steroids and those who haven't.\n",
    "\n",
    "3. Antivirals (1 = No, 2 = Yes): The majority of individuals have taken antiviral drugs. Patients even after taking antiviral drugs have died but majority of them have lived.\n",
    "\n",
    "4. Fatigue (1 = No, 2 = Yes): Fatigue seems prevalent in the dataset, with most individuals experiencing it.Both classes show a significant presence of fatigue, some patients without fatigue have also died which suggests it may not be a differentiator.\n",
    "\n",
    "5. Malaise (1 = No, 2 = Yes): Malaise is also common in the dataset, with most individuals experiencing it. Similar to fatigue, malaise is present in both classes.\n",
    "\n",
    "6. Anorexia (1 = No, 2 = Yes): Anorexia also seems common, with most individuals experiencing it but does not seem to be of any affect to Hepatits.\n",
    "\n",
    "7. Liver_Big (1 = No, 2 = Yes): The majority of individuals have an enlarged liver. Patients with big liver seem to have some death due to Hepatits.\n",
    "\n",
    "8. Liver_Firm (1 = No, 2 = Yes): Firm liver is predominant in the dataset. But unlike Liver_Big, people without firm liver also seem to die because of the disease. \n",
    "\n",
    "9. Spleen_Palpable (1 = No, 2 = Yes): Most individuals have a palpable spleen. The distribution across classes is fairly consistent, suggesting spleen palpability may not be a strong indicator.\n",
    "\n",
    "10. Spiders(1 = No, 2 = Yes): Spider veins are common, with the majority having them. And with respect to Class, patients without spider viens have more deaths than with. \n",
    "\n",
    "11. Ascites (1 = No, 2 = Yes): Ascites is more common, with the majority having it. The distribution across classes is somewhat balanced, with both classes having individuals with and without ascites.\n",
    "\n",
    "12. Varices (1 = No, 2 = Yes): Varices are more common, with the majority having them. The distribution across classes is somewhat balanced, with both classes having individuals with and without varices.\n",
    "\n",
    "13. Histology(1 = No, 2 = Yes): Most individuals have a histology value of 1.0 meaning there number of patients with histology is very less. And for class distribution, the patients with histology have higher chance of being in non-survivor class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fd708",
   "metadata": {},
   "source": [
    "### 2.4. Contingency Table for further confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7704788",
   "metadata": {},
   "source": [
    "#### Contingency Table for 'Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime' attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae02c9",
   "metadata": {},
   "source": [
    "Comparing the mean of the mentioned groups with each \"Class\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa270da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in num_vars:\n",
    "    class_1 = df_no_outliers[df_no_outliers['Class'] == 1][var]\n",
    "    class_2 = df_no_outliers[df_no_outliers['Class'] == 2][var]\n",
    "    t_stat, p_value = ttest_ind(class_1, class_2)\n",
    "    print(f'Test for {var}: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3fbfa",
   "metadata": {},
   "source": [
    "1. Age:\n",
    "p-value = 0.1030\n",
    "With a p-value of 0.1030, we fail to reject the null hypothesis at a significance level of 0.05. There is not enough evidence to conclude that there is a significant difference in the mean age between two values of Class.\n",
    "2. Bilirubin:\n",
    "p-value = 0.0153\n",
    "The p-value of 0.0153 is less than the significance level of 0.05. Therefore, we reject the null hypothesis. This suggests that there is a significant difference in the mean bilirubin levels between  two values of Class.\n",
    "3. Alk_Phosphate:\n",
    "p-value = 0.1971\n",
    "The p-value of 0.1971 is greater than the significance level of 0.05. Thus, we fail to reject the null hypothesis. There is not enough evidence to conclude that there is a significant difference in the mean alkaline phosphatase levels between two values of Class.\n",
    "4. Sgot:\n",
    "p-value = 0.5311\n",
    "With a p-value of 0.5311, we fail to reject the null hypothesis at a significance level of 0.05. There is not enough evidence to suggest a significant difference in the mean serum glutamic oxaloacetic transaminase levels between two values of Class.\n",
    "5. Albumin:\n",
    "p-value = 0.0000\n",
    "The p-value is less than 0.05, indicating strong evidence to reject the null hypothesis. There is a significant difference in the mean albumin levels between two values of Class.\n",
    "6. Protime:\n",
    "Result: p-value = 0.1407\n",
    "The p-value of 0.1407 is greater than the significance level of 0.05. Therefore, we fail to reject the null hypothesis. There is not enough evidence to conclude that there is a significant difference in the mean prothrombin time levels between two values of Class.\n",
    "\n",
    "In summary, based on a significance level of 0.05:\n",
    "Bilirubin and Albumin levels show significant differences between Class 1 and Class 2 patients.\n",
    "Age, Alk_Phosphate, Sgot, and Protime do not show significant differences between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5173640",
   "metadata": {},
   "source": [
    "#### Contingency table for 'Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver_Big', 'Liver_Firm', 'Spleen_Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d73f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in nonnum_vars:\n",
    "    contingency_table = pd.crosstab(df_no_outliers[var], df_no_outliers['Class'])\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f'Chi-Square Test for {var}: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d00d7",
   "metadata": {},
   "source": [
    "1. Sex: p-value = 0.2463\n",
    "2. Steroid: p-value = 0.5227\n",
    "3. Antivirals: p-value = 0.3272\n",
    "4. Anorexia: p-value = 0.6789\n",
    "5. Liver_Big: p-value = 0.1635\n",
    "6. Liver_Firm:p-value = 1.0000\n",
    "7. Spleen_Palpable: p-value = 0.0707\n",
    "Explanation for the parameters above: The p-value of 0.0707 is greater than the significance level of 0.05. Thus, we fail to reject the null hypothesis. There is not enough evidence to suggest a significant association between palpable spleen and class.\n",
    "\n",
    "8. Fatigue: Result: p-value = 0.0170\n",
    "9. Malaise: Result: p-value = 0.0125\n",
    "10. Spiders: Result: p-value = 0.0001\n",
    "11. Ascites: Result: p-value = 0.0000\n",
    "12. Varices: Result: p-value = 0.0001\n",
    "13. Histology: Result: p-value = 0.0001\n",
    "Explanation for the parameters above: The p-value is less than 0.05, indicating strong evidence to reject the null hypothesis. There is a significant association between histology and class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb84bbc",
   "metadata": {},
   "source": [
    "### 2.5. Kernel Density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['Age', 'Bilirubin', 'Alk_Phosphate', 'Sgot', 'Albumin', 'Protime']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "fig.suptitle('KDE Plots for Variables with Significant Associations', fontsize=16)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(num_vars):\n",
    "    sns.kdeplot(data=df_no_outliers, x=var, hue='Class', fill=True, common_norm=False, ax=axes[i], palette='Set2')\n",
    "    axes[i].set_title(f'KDE Plot for {var}')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6965e0d",
   "metadata": {},
   "source": [
    "# 3. CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0361f18",
   "metadata": {},
   "source": [
    "The dataset provided for Hepatitis included with various numerical and categorical attributes was imported and various analysis, visualization, inspection and cleaning was conducted to investigate what sort of information could be extracted and what kind of prediction can we make from the dataset. \n",
    "\n",
    "Initially, the data was given some descriptive attribute names (column names) and with the features in python, we tried to learn more about the distribution, description and shape of data. It was clear that there were missing and misleading values in the dataset for which several steps were taken to clear the dataset with misleading values and use backfill to fill out the missing values. \n",
    "\n",
    "The major goal of the project was to determine if a patient is going to live or die if they contract Hepatitis i.e. \"Class\" is our target variable and all other are reponse variable. During data analysis, various plots and diagrams were used to visualize the distribution of data, figure out the correlation between attributes and also determine outliers. The outliers were cleared using inter-quartile range values. Since, the dataset has numeric and categorical attributes, separate tests were done to get the idea about each type of attributes. We concluded that being male has higher chances of contracting the disease and also some males who contract the disease might not survive. Similarly, all other attributes were compared to figure out what kind of significance they had to our target variable. And finally for further confirmation, simple hypothesis testing was done with p-value and $\\alpha = 0.05.$\n",
    "\n",
    "In summary, all the processes carried out in this project is a compilation of what we learned in class. And the learnings were used to determine the properties of various parameters with respect to the \"Class\" attribute of the dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
